---
title: "Final Assignment"
output: html_document
date: "2024-03-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction
For this project we are going to be using the STAR dataset which is an experiment conducted in the 1980s that tried to evaluate the effectiveness of class sizes on test scores. For this project we are going to be focusing on the effects of class size on first grade math scores. Specifically we want to see if there is any difference in first grade math scores across different class sizes and if so what class size is the most effect in increasing test scores.

# Background and Motivation
In 1985, Tennessee passed legislation giving funding to test a policy study to determine the effects of class size on student achievement in primary grades. The main questions asked during this study are:

1. What are the effects of reduced class size on achievement (criterion tests) and development of students in public elementary school grades k-3.
2. Is there a cumulative effect of being in a small class size over an extended time (4 years) as compared with students in a small class size over a single year?
3. Does training program designed to help teachers maximize small classes or training which helps teachers effectively use aides improve student performance over teachers with no special training?

# Experimental Design and Criticisms
For the experiment, students who enrolled in schools participating in the experiment (of which there were 79 schools participating) were randomly assigned to one of three classrooms:

1. Small (17 students maximum)
2. Regular(22-25)
3. Regular + Aide (22-25)

From there a scores for students would be tracked and analysed to see if class type had an effect. In total 11,601 students were observed throughout the experiment, however of this total only 26% fully participated in the STAR project for all four consecutive years (k-3)

This is a point of criticism in the design of the experiment as only having about 1/4 of the total participants managing to participate in the original design experiment would most likely effect the data observed. This however, is an expected outcome as students were not forced to participate in the experiment and switching classes or schools due to external circumstances is simply a fact of life. Another issue from a design standpoint is that kindergarten in Tennessee is not required (at least during the time of the experiment) which means a lot more students participating started at 1st grade. This is further emphasized by the fact (as mentioned before) only 26% fully participated in the original experiment design. Because of this, even though it may not have entirely answered the effects of small class sizes on early development, it may have been better to start the experiment in 1st grade rather than kindergarten. 

Additionally, classroom shift is an issue for this study. Classroom shift is when a student moves from one classroom to another (small -> regular etc). The dataset tries to alleviate this by including tags that extract information on these shifts called CMPSTYPE and CMPSDURA. CMPSTYPE is a flag which indicates the type of classroom they were in and CMPSDURA measure how long they were in said classroom. The issue with CMPSTYPE is that should a student move in and out of a small classroom at least once, for example s->r->s or s->s->r->s then they are tagged as missing. In addition they are also tagged as missing should they join a small classroom past 1st grade. This removes a lot of information that could be gleaned from these shifts but may also help simplify analysis depending on the goal of the analysis. Because of these shifts, another issue arises where classes tagged as regular may reduce to ranges not specified (18-21) or may even reach  levels of small class sizes. Similarly, small class sizes could reach ranges that are not specified (11-12). However, even with all these issues, the experiment design should not be discounted. It still helps glean information on the importance of class size in children development and should not be ignored due to these issues that arise due to shifts that occur naturally in life. Instead these issues should be taken into account when analysing the data so as to not make incorrect conclusions.

# Caveats
In the initial analysis report, I found some issues with the model used. Firstly, one main assumption used in the model is that there were equal number of samples for eat treatment level. However, the number of samples in each treatment (schoolid and classroomtype) were imbalanced which would lead to problems in the analysis. In addition, another assumption was that $\{e_{ijk}\} \overset{\mathrm{iid}}{\sim} N(0, \sigma^2)$ which when looking at the normal QQ plot was most likely not true under the original model. 

Additionally, the original model only looked at school id (due to it being a stratified design) and class size as factors. However, there may be other factors that should be taken into account, for example socioeconomic factors or ethnicity may play a role in addition to other factors such as teacher education etc. This should be further inspected.

Finally, there was a lot of missing data throughout the dataset and should be further analysed to see if patterns emerged in key factors that may be used in the final model.

# EDA

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(haven)
library(foreign)
```

```{r, warning=FALSE, echo=FALSE}
df = read.spss("Data/STAR_students.sav", to.data.frame=TRUE)
df1 = read.spss("Data/STAR_K-3_Schools.sav", to.data.frame=TRUE)
```

```{r, echo=FALSE, include=FALSE}
head(df)
```

```{r}
missing <- df %>% 
  group_by(g1schid) %>%
  summarize(count = n_distinct(g1classtype)) %>%
  filter(count <=2)
```



```{r}
missing %>%
  inner_join(df, by = "g1schid") %>%
  select(g1schid, g1classtype) %>%
  distinct() %>%
  arrange(g1schid, g1classtype)
```
Out of all the schools participating in this experiment, there were 4 schools that were missing one of the treatment groups. In all 4 cases each school was missing the regular + aide class.

```{r}
id_missing <- missing %>%
  inner_join(df, by = "g1schid") %>%
  select(g1schid) %>%
  distinct()
```




```{r}
missing %>%
  inner_join(df1, by=c('g1schid' = 'schid')) %>%
  select(c('g1schid', 'SCHLURBN'))
```

Of these schools, 3 of the four were inner city schools and only 1 was a suburban school. None of the schools missing regular + aide treatment came from urban or rural schools.

```{r, echo=FALSE}
proportion_first_grade_free <- df %>%
  inner_join(df1, by=c('g1schid' = 'schid')) %>%
  group_by(SCHLURBN) %>%
  summarize(student_count = n(),
            prop = sum(g1freelunch=="FREE LUNCH", na.rm=TRUE)/n())


ggplot(proportion_first_grade_free, aes(x=SCHLURBN, y=prop)) +
  geom_bar(stat = 'identity', color='black') +
  labs(x = "School Type", y = "Proportion of 1st grade students with Free Lunch", title = "Proportion of 1st Grade Students with Free Lunch by School") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

When grouping by the school type, we can see that in first grade there were about 90% of children in Inner City schools who are on a free or reduced lunch plan while the next highest (urban) is around 44%. This is consistent with the background where inner city schools were determined based on the number of students  on a free lunch plan. Because of this, I believe it may be good to utilize school type as a measure of socioeconomic class. However, another potential factor that could be used to determine socioeconomic status is whether the student themselves has free lunch. One or the other or both may be a potential treatment that could be used when building an ANOVA model. If school type is used, it may help extract information on overall school funding while individual student lunch status may extract information on a student's socioeconomic status. 

```{r, echo=FALSE, warning=FALSE}
suburban_free <- df1 %>%
  filter(SCHLURBN == "SUBURBAN") %>%
  select(schid, G1FRLNCH)

suburban_free$highlight <- ifelse(suburban_free$schid %in% id_missing$g1schid, "missing_aide", "regular")


ggplot(suburban_free, aes(x=as.factor(schid), y=G1FRLNCH, fill=highlight, na.rm = TRUE)) +
  geom_bar(stat = 'identity', color='black') +
  scale_fill_manual(values = c("regular" = "skyblue", "missing_aide" = "orange")) +  # Adjust colors as needed
  labs(x = "School ID", y = "Proportion of Students with Free Lunch", title = "Proportion of Students with Free Lunch by Suburban Schools") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```
Looking at suburban schools, the one missing the aide class is not very different in terms of students with free lunches compared to other suburban schools. This means at least the proportion of students having free lunch (and by extension socioeconomic status) did not affect why the school was missing one of the treatment group.

```{r, echo=FALSE, warning=FALSE}
#graph free lunch for inner city school and demographics
innercity <-  df1 %>% filter(SCHLURBN=='INNER CITY') %>%
  select(schid, G1FRLNCH, G1ASIAN, G1BLACK, G1HSPANC, G1WHITE, G1OTHRAC)

innercity$highlight <- ifelse(innercity$schid %in% id_missing$g1schid, "highlight", "regular")

ggplot(innercity, aes(x=as.factor(schid), y=G1FRLNCH, fill=highlight, na.rm = TRUE)) +
  geom_bar(stat = 'identity', color='black') +
  scale_fill_manual(values = c("regular" = "skyblue", "highlight" = "orange")) +  # Adjust colors as needed
  labs(x = "School ID", y = "Proportion of Students with Free Lunch", title = "Proportion of Students with Free Lunch by School") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```
Similarly for Inner city schools, the proportion of students with free lunch is not very different when comparing those that were missing a treatment group and those that had all 3 treatment groups.

```{r}
strings_to_search <- c("G1NATVAM", "G1ASIAN", "G1BLACK", "G1HSPANC", "G1WHITE", "G1OTHR")

# Group by school ID and calculate the total student population

pop <- df1 %>%
  select(c('schid', contains(strings_to_search), 'SCHLURBN')) %>%
  summarize(
    schid,
    SCHLURBN,
    total_population = rowSums(select(., contains(strings_to_search)), na.rm=TRUE)
  )

pop$highlight <- ifelse(pop$schid %in% id_missing$g1schid, "missing_aide", "regular")

ggplot(pop, aes(x=as.factor(schid), y=total_population, fill=highlight, color=SCHLURBN, na.rm = TRUE)) +
  geom_bar(stat = 'identity', color='black') +
  scale_fill_manual(values = c("regular" = "skyblue", "highlight" = "orange")) +  # Adjust colors as needed
  labs(x = "School ID", y = "Population of G1 Students", title = "Student Population") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Another potential reason that the four schools were missing a grade 1 teacher aide class in the experiment was that perhaps they did not have enough students to fulfill the classroom requirements and therefore chose to forgo the teacher + aide class. However, upon further inspection, it is evident that at least for grade 1 that there were enough students to participate in all 3 class types in addition, the schools that were missing the aide treatment had similar g1 population to other schools.

Currently there are no discernible patterns on why these 4 schools were missing teacher aide class so it with the current knowledge it is believable to say that it is missing at random. In addition, according to the background, after the first set of students transitioned from kindergarten to first grade, they saw no discernible difference between regular classroom and regular + aide classroom. Therefore, it should not pose a problem to ignore the fact that these schools are missing a treatment.



For the final dataset, all information from 4th grade to highschool will be ignored. Even though it would be interesting the long term effects class size during early development had past the initial experiment the goal of this analysis is primarily on 1st grade math scores and therefore this information would most likely not be impactful towards this goal. In addition to this, I will be ignoring 3rd grade information as well. The reason for this is that I want to include kindergarten and second grade as they are directly before and after first grade so any effects that kindergarten had on first grade and first grade effects on second grade may be prudent to look at. Furthermore, for missing data I believe that kindergarten and second grade information most likely provides enough for imputation and analysis on why things may be missing.

```{r, include=FALSE}
filtered_df <- df %>%
  select(-contains("g3"), -contains("g4"), -contains("g5"), -contains("g6"), -contains("g7"), -contains("g8"), -starts_with("hs"), -contains("flagidn8")) 

filtered_df1 <- filtered_df %>%
  filter(!is.na(g1tmathss))
  
filtered_df1
```

Looking through the data which has a grade 1 math score, all of them were participating in the grade 1 star project. This means the students missing grade 1 math score should be looked at to see if there are any patterns and information that could be extracted.

```{r, include=FALSE}
na_filtered <- filtered_df %>%
  filter(is.na(g1tmathss))

count_data <- table(na_filtered$FLAGSG1)

# Create a bar plot of count of YES and NO values
ggplot(data.frame(Response = names(count_data), Count = as.numeric(count_data)), aes(x = Response, y = Count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_text(aes(label = Count), vjust = -0.5, color = "black", size = 3) +
  labs(x = "Response", y = "Count", title = "Number of Students Participating in G1 Star and Missing Math Score") +
  theme_minimal()
```

Of the students missing a math scores there was a small subset which were actually participating in the grade 1 star project and a larger subset who were not participating in grade 1. The small subset should be looked at to see if any patterns emerge and from the students who were not participating in grade 1, I will be subsetting to use only those participating in kindergarten and assume that they would have participated in the same class size if they were participating in grade 1.


```{r}
na_filtered_yes <- na_filtered %>%
  filter(FLAGSG1 == "YES")

ggplot(na_filtered_yes, aes(x = gender)) +
  geom_bar(fill = "skyblue") +
  labs(x = "Gender", y = "Count", title = "Counts of Male and Female") +
  theme_minimal()

```

```{r}
ggplot(na_filtered_yes, aes(x=race)) +
  geom_bar(fill="skyblue") +
  labs(x="Gender", y="Count", title="Count of Gender")
```

```{r}
ggplot(na_filtered_yes, aes(x=g1surban)) +
  geom_bar(fill="skyblue") +
  labs(x="Living Area Classification", y="Count", title="Student Living Area Classification")
```

```{r}
a <- na_filtered_yes %>%
  summarize(NA_count = sum(is.na(g1treadss)),
            non_NA = sum(is.na(g1treadss)))

count_data_long <- tidyr::pivot_longer(a, cols = c(NA_count, non_NA), names_to = "Category", values_to = "Count")

# Create a bar plot
ggplot(count_data_long, aes(x = Category, y = Count, fill = Category)) +
  geom_bar(stat = "identity") +
  labs(x = "Category", y = "Count", title = "Count of NA and non-NA Values") +
  scale_fill_manual(values = c("skyblue", "orange"), labels = c("NA", "Non-NA")) +
  theme_minimal()
```

Looking at the 3 graphs above, it is very difficult to see why these students were missing a grade 1 math score even though they were participating in the STAR project during grade 1. Looking at gender, it seems as though males were more likely to miss a grade 1 score but females also had a non significant amount of students missing as well meaning it is difficult to use gender as an underlying pattern. Similarly, although students living in rural areas are more likely to be missing a grade 1 score, other areas were missing a decent amount of grade 1 tests information proportionally speaking. This means, that similar to gender, where a student was living (and potentially by extension their socioeconomic status) is not an underlying factor to why the variable is missing. Another potential pattern was seeing if a student that did not have a reading score would also be missing their math score. However, upon further examination in the graph above, approximately half of the students who had a reading score were missing their math score meaning this was also a not good indicator for why students were missing a math score. Because of this it is difficult to determine a pattern of missingness and therefore I will be ignoring these students whow were missing a math score even though they were participating in the g1 STAR project.  This may have been due to different errors such as the students were absent or maybe there was an error while inputting the data (some students were missing gender or race for example). Either way because of the difficulty in determining a pattern given the current data, I will be removing the students who were missing a grade 1 math score who were also participating in the grade 1 STAR project.


It is similarly difficult to determine why students who were participating in kindergarten project STAR were missing either kindergarten reading or math scores. Therefore, I will be removing students who were missing either of this information (assuming that they were also missing grade 1 math score). This will allow for a model to be made that will impute g1math scores based on their kindergarten reading and math scores. It is also important to note that only around 200 students of the 1800 students were removed when filtering for this criteria so hopefully not a lot of information was lost.

```{r}
na_filtered_no <- na_filtered %>%
  filter(FLAGSG1 == "NO")

kinder_flag <- na_filtered_no %>%
  filter(FLAGSGK == "YES")

kinder_flag <- kinder_flag %>%
  mutate(g1classtype = ifelse(is.na(g1classtype), as.character(gkclasstype), g1classtype))

kinder_flag <- kinder_flag %>%
  filter(!is.na(gktreadss) & !is.na(gktmathss))

kinder_flag <- kinder_flag %>%
  mutate(g1schid = ifelse(is.na(g1schid), gkschid, g1schid))

combined <- unique(rbind(filtered_df1, kinder_flag))

combined <- combined %>%
  mutate(g1schid = ifelse(is.na(g1schid), gkschid, g1schid))
```



```{r}

both <- combined %>%
  filter(!is.na(gktreadss) & !is.na(gktmathss) & !is.na(g1tmathss))

pred_model <- lm(g1tmathss ~ gktreadss + gktmathss, data=both)
anova(pred_model)

```

This is a simple model used for imputation, it looks at a child's kindergarten math and reading scores to predict their first grade math and reading scores. Looking at the anova table, the model does well job in predicting grade 1 math scores. It is important to note that I did not use class size in this model because it would be counterintuitive to use class size to predict math scores and impute those values when I want to analyse the effects of class size has on a student's math score.


```{r}

predictor_columns <- names(pred_model$model)[-1]


df_subset <- kinder_flag[complete.cases(kinder_flag[, predictor_columns]), predictor_columns]

predicted_values <- predict(pred_model, newdata = df_subset)





kinder_flag$g1tmathss[is.na(kinder_flag$g1tmathss)] <- predicted_values[is.na(kinder_flag$g1tmathss)]

kinder_flag$g1tmathss <- as.integer(kinder_flag$g1tmathss)


```

```{r}
combine <- unique(rbind(filtered_df1, kinder_flag))

combine_id <- combine %>%
  inner_join(df1, by=c("g1schid" = "schid"))

combine_id <- combine_id %>%
  mutate(g1freelunch = ifelse(is.na(g1freelunch), as.character(gkfreelunch), as.character(g1freelunch)))
combine_id <- combine_id %>%
  filter(!is.na(g1freelunch))


combine_id$g1freelunch <- gsub("NON-FREE", "NON_FREE", combine_id$g1freelunch)

combine_id$g1classtype <- gsub("\\+", "", combine_id$g1classtype)


```

In summary this is how the data was cleaned:

1. removed 3->high school data
2. retrieved all the students that had available data on their grade 1 math scores
3. looked into the distribution of students that were missing grade 1 math scores
  + removed students that were part of grade 1 project STAR but also missing their grade 1 math score
4. included students that were participating in project STAR during kindergarten but were missing in grade 1
  + imputed these students under the assumption that they would have stayed in the class type when transitioning to grade 1 assuming they were still in the project
  + similarly imputed their grade 1 school id under the assumption their kindergarten school would have been their 1st grade school
    - of these students removed those that were missing either their kindergarten reading or math scores
5. imputed grade 1 free lunch status for missing elements based on the free lunch status when they were in kindergarten
  + removed the remaining students that did not have any information on their free lunch status in either kindergarten and first grade (only around 30 students)
6. created a linear model that used kindergarten reading and math scores to predict grade 1 math scores
7. imputed the missing math scores using the model
8. Joined this dataset with the k-3 school information to glean information on the schools the students were attending

```{r}

student_count <- table(combine$g1schid)
student_count_df <- as.data.frame(student_count)
student_count_df$Var1 <- as.character(student_count_df$Var1)

ggplot(student_count_df, aes(x=Var1, y=Freq)) +
  geom_bar(stat="identity")+
  labs(x="School ID", y="Number of Students", title= "Number of Students at a specific School") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Looking at the graph above, the number of students at each school is not very equal. This observation should be taken into account when looking at an anova model to use.

```{r, warning=FALSE}
library(gplots)
```


```{r}
ggplot(combine, aes(x=g1tmathss))+
  geom_density(fill='skyblue', color='black')+
  labs(x="math scores", y='density', title="kernel density of student's math score")
```

Looking at the kernel density plot, the math scores potentially follows an approximate normal distribution. Because of this, I will model this data at the student level rather than the teacher level as previously done in the initial analysis report.

```{r, warning=FALSE}

par(mfrow = c(1,2))

plotmeans(g1tmathss~g1classtype,data=combine_id,xlab="class size",ylab="average math scores",
          main="Main  effect, class size",cex.lab=1.5) 

```

```{r, warning=FALSE}

plotmeans(g1tmathss~g1freelunch, data=combine_id, xlab="School Location", ylab='Math Scores',
          title='Main Effect Plot of Free lunch status on ')


```

```{r}
interaction.plot(combine_id$g1classtype, combine_id$g1freelunch, combine_id$g1tmathss
                ,cex.lab=1.5,ylab="Average Math Score",xlab='Class Size')
```


ASK ABOUT MAKING THIS CLEANER
```{r, warning=FALSE}
plotmeans(g1tmathss~g1schid, data=combine_id)
```

# Model Creation

Given my initial analysis of the data the current model proposed is $Y_{ijkl} = \mu_{...} + \alpha_i + \beta_j + \gamma_l + \epsilon_{ijkl}$ where:

\begin{align}

\mu_{...} &= \text{ overall average math score for a student} \\
\alpha_i &= \text{ the effect of the ith class size on a student's math score} \\
\text{i = 1,...,3} \\
\beta_j &= \text{ the effect of free lunch status on a student's math score} \\
\text{j = 1,2} \\
\gamma_l &= \text{ the effect of the lth school id on a student's math score} \\
\text{l = 1,...,75} \\

\end{align}

Similarly the model follows a few assumptions, the main one being: $\epsilon_{ijkl} \overset{\mathrm{iid}}{\sim} N(0, \sigma^2)$

Looking at the main effect plots for both class type and free lunch status, it is evident that an effect is most likely present for both treatments on grade 1 math scores. In addition, the interaction plot between the two variables are roughly parallel meaning that there is very little interaction effect between the two treatments. So the proposed model is just looking at the individual treatment effects while including the school id as it is normal convention for a stratified experiment.

```{r}
library(car)
combine_id$g1schid <- as.factor(combine_id$g1schid)
#Given that interaction seems to be significant it may be prudent to include it
t1=aov(g1tmathss~g1freelunch + g1classtype + g1schid, data=combine_id)

summary(t1)


```

```{r}
data.frame(Coefficients = unlist(t1$coefficients[2:4]))
```

```{r}
id_coef <- t1$coefficients[5:length(t1$coefficients)]

data.frame(Coefficients = unlist(id_coef))

ggplot(data.frame(Coefficients = unlist(id_coef)),aes(x="",y=Coefficients)) +
  geom_violin(fill="skyblue", color='black', alpha=0.6)+
  geom_point(aes(y=mean(Coefficients)), size=4, color='red') +
  geom_jitter(width=0.05, height=0) +
  labs(x=NULL, y="Coefficient Values", title="Violin plot of the Coefficient Values of schoolid")
```

The model proposed includes a student's grade 1 free lunch status as well as class type and school id. The model assumes no interaction which is similar to the model proposed in the initial analysis. The main differences is the inclusion of free lunch status, analyzing at the student level, and a deeper analysis on how the data was cleaned and which subjects were used for the model. The conclusions are similar to the initial analysis which concluded that both class type and schoolid had an effect on grade 1 math scores. The model in this case adds that along with class type and schoolid, a student's free lunch status is an important treatment factor as well. 

# Sensitivity Analysis


```{r}

plot(t1, which=1:2)
```

The main assumptions that are being checked for the model is seeing if the error terms (residuals) follows a normal distribution and if the variance of the residuals is fairly constant. Looking at the residual vs fitted plot, the overall spread of the residuals does not fan out as the x-axis increases which indicates that the residuals most likely has a constant variance throughout. The QQ plot is a plot that graphs how consistently the residuals follows a normal distribution. Any deviation from the given line most likely indicates deviations from a normal distirubtion. In this case, there is a lot of deviation from the line around the 2-4 theoretical quantile area meaning that there is a bit of right skewness when compared to a normal distribution. This indicates that the normality assumption is most likely violeted but more tests may be performed to see if this conclusion is further supported.


```{r}

residuals <- residuals(t1)


# 2. Create a histogram of the residuals
ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
  geom_histogram(aes(y=after_stat(density)),binwidth = 0.5, color = "skyblue", alpha = 0.7, bins=60) +
  geom_density(color='red')+
  labs(x = "Residuals", y = "relative frequency", title = "Histogram of Residuals")


```

Graphing the residuals through a histogram and a kde plot. It is evident that there is some slight bell shape which may indicate a normal like distribution. However, this alone does not support the fact that the residuals are following a normal distribution and given the qqplot should be taken with some skepticism.

Instead a test for normality can be used to see whether a normal assumption is valid. Due to the limitations of a shapiro wilkes test (the package requires the sample to be between 3-5000 in length while currently the sample size is around 8000) I will be using an Anderson-Darling test. The Anderson-Darling test will test the following hypothesis:

$H_o:$ The residuals follows a normal distribution.
$H_a:$ The residuals is not normally distributed.

```{r}
library(nortest)
ad.test(residuals)
```

Looking at the test, the p-value is very close to 0 meaning that at $\alpha=0.05$ the null hypothesis is rejected. Because of this as well as the normal qqplot observations, it is most likely safe to conclude that the residuals do not follow a normal distribution and therefore the normality assumption is not valid.

Because of this conclusion, it is prudent to see if a non parametric analysis in which the normality assumption is not required also results in similar conclusions to our model.

```{r}
combine_id$rank <- rank(combine_id$g1tmathss)

summary(aov(rank~g1freelunch + g1classtype + g1schid, data=combine_id))
```

Above is a rank-test anova model. It provides similar conclusions that the original model makes that class type as well as free lunch are both important factors in determining grade 1 test scores. Because of this, even though the original model may not meet the normality assumption, it's conclusions is still most likely valid. 

Another problem that should be checked is the fact that the treatment groups do not have equal sample size. Below is a violin plot which shows the general distribution of number of students per treatment group. Looking at it, most groups fall between around 5-30 while only a few groups going past 40. Due to this unequal sample size, the type I test utilized which does a sequential algorithm may result in a different conclusion if the order of treatment groups is changed. It is important to check if this is the case and whether or not the conclusion changes due to this.

```{r, warning=FALSE}
df_num_students <- combine_id %>%
  group_by(g1schid, g1freelunch, g1classtype) %>%
  summarize(num_students = n())

ggplot(data=df_num_students, aes(x="", y=num_students))+
  geom_violin(fill='skyblue') +
  geom_jitter(height=0.05, width=0.1) +
  geom_point(aes(y=mean(num_students)), color='red', size=4)
```

Looking at the three tables below, the order of the treatment variables were changed to see if there were any changes to the conclusion as well as the change in their sum of squares. In this case, the conclusion for each of these does not change. Similarly, even though the mean squared treatment changes when order changes, it does not change significantly most likely indicating that even though the sample size is uneven the original model is valid to use. In addition, another question about the effect that the interaction between freelunch status and class type may have on test scores. The graph shown before showed that the interaction most likely did not have an effect. When proposing an anova

```{r}
summary(aov(g1tmathss~g1classtype + g1schid + g1freelunch, data=combine_id))
summary(aov(g1tmathss~g1schid + g1classtype + g1freelunch, data=combine_id))
summary(aov(g1tmathss~g1schid + g1freelunch + g1classtype, data=combine_id))
summary(aov(g1tmathss~g1freelunch*g1classtype + g1schid, data=combine_id))
```





